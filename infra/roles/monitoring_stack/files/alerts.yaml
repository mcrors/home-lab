groups:
  - name: availability
    rules:
      - alert: NodeDown
        expr: up{job=~"node-exporter|node"} == 0
        for: 2m
        labels:
          severity: critical
        annotations:
          summary: "Node down: {{ $labels.instance }}"
          description: "Prometheus cannot scrape {{ $labels.instance }} (job={{ $labels.job }}) for 2 minutes."

      # Optional: network-level check (needs blackbox_exporter 'icmp' or 'http' probe set up)
      # - alert: HostPingFailed
        # expr: probe_success{job="blackbox-icmp"} == 0
        # for: 2m
        # labels:
          # severity: critical
        # annotations:
          # summary: "Host not reachable: {{ $labels.instance }}"
          # description: "ICMP probe to {{ $labels.instance }} failing."

  # - name: events
    # rules:
      # 2) NODE RESTARTED RECENTLY
      # - alert: NodeRebooted
        # expr: changes(node_boot_time_seconds[5m]) > 0
        # for: 0m
        # labels:
          # severity: info
        # annotations:
          # summary: "Node rebooted: {{ $labels.instance }}"
          # description: "Uptime is now {{ humanizeDuration(time() - node_boot_time_seconds) }}."

      # (K3s/k8s) Container restarts (needs kube-state-metrics)
      # - alert: PodContainerRestarted
        # expr: increase(kube_pod_container_status_restarts_total[5m]) > 0
        # for: 0m
        # labels:
          # severity: warning
        # annotations:
          # summary: "Pod container restarted in {{ $labels.namespace }}: {{ $labels.pod }} / {{ $labels.container }}"
          # description: "Restart count increased in the last 5 minutes."

      # (Docker/cAdvisor) Container restarted (needs cAdvisor on hosts)
      # - alert: ContainerRestarted
        # expr: changes(container_start_time_seconds{image!=""}[5m]) > 0
        # for: 0m
        # labels:
          # severity: warning
        # annotations:
          # summary: "Container restarted: {{ $labels.instance }} {{ $labels.name }}"
          # description: "Container start time changed in the last 5 minutes."

  - name: health
    rules:
      # CPU
      - alert: HighCPUUsage
        expr: avg by (instance) (rate(node_cpu_seconds_total{mode!="idle"}[5m])) > 0.90
        for: 5m
        labels:
          severity: warning
        annotations:
          summary: "High CPU on {{ $labels.instance }}"
          description: "Average CPU > 90% for 5 minutes."

      # Memory pressure (MemAvailable < 10%)
      - alert: LowMemoryAvailable
        expr: (node_memory_MemAvailable_bytes / node_memory_MemTotal_bytes) < 0.10
        for: 5m
        labels:
          severity: warning
        annotations:
          summary: "Low memory on {{ $labels.instance }}"
          description: "Less than 10% memory available."

      # Disk space low (any real fs)
      - alert: DiskSpaceLow
        expr: (node_filesystem_avail_bytes{fstype!~"tmpfs|overlay|squashfs"} / node_filesystem_size_bytes{fstype!~"tmpfs|overlay|squashfs"}) < 0.10
        for: 10m
        labels:
          severity: warning
        annotations:
          summary: "Disk space low on {{ $labels.instance }} ({{ $labels.mountpoint }})"
          description: "Free space < 10%."

      # Disk will fill soon (project into the future)
      - alert: DiskWillFillSoon
        expr: predict_linear(node_filesystem_free_bytes{fstype!~"tmpfs|overlay|squashfs"}[6h], 4*3600) < 0
        for: 15m
        labels:
          severity: warning
        annotations:
          summary: "Disk may fill within 4 hours on {{ $labels.instance }} ({{ $labels.mountpoint }})"
          description: "Trend suggests free space will hit 0 within ~4 hours."

      # Filesystem turned read-only (bad sign)
      - alert: FilesystemReadOnly
        expr: node_filesystem_readonly{fstype!~"tmpfs|overlay|squashfs"} == 1
        for: 2m
        labels:
          severity: critical
        annotations:
          summary: "Read-only filesystem on {{ $labels.instance }} ({{ $labels.mountpoint }})"
          description: "Filesystem flipped to read-only."

      # Systemd unit failures (needs node_exporter textfile or systemd collector enabled)
      # - alert: SystemdUnitFailed
        # expr: node_systemd_unit_state{state="failed"} == 1
        # for: 2m
        # labels:
          # severity: warning
        # annotations:
          # summary: "Failed systemd unit on {{ $labels.instance }}: {{ $labels.name }}"
          # description: "A systemd unit is in 'failed' state."
